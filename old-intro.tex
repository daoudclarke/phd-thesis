%\input{introduction.tex}

%\chapter{An Algebraic Vision}

%%\section{Introduction}

%\dropcap{T}\textsc{he aim of this thesis} is to promote an algebraic approach to computational linguistics. It is our strong belief that certain areas of algebra are very well suited to capturing the shades of meaning and vagueness inherent in natural language, and combining these with a strong probabilistic foundation. Our studies have led us gradually to one specific area, that of \emph{vector lattices} and \emph{positive operators} on these lattices. In fact, our essential thesis may be stated as follows: \emph{The meaning of a word can be represented as a positive operator}.
%%\footnote{The mathematical reader should note that the sense of this term that is intended here is that of Aliprantis and Burkinshaw, i.e.~an operator on a vector lattice, and not that of an operator whose spectrum is a subset of the non-negative real numbers.}}\index{positive operator}.
%Our efforts from now on are devoted to explaining what this statement means, and justifying it as far as we are able.

% We believe there are many benefits to such an approach, as well as some disadvantages. The benefits stem from the ability to combine and compare techniques from diverse areas of computational linguistics within a unified and consistent formalism. Techniques and formalisms such as latent semantic analysis, semantic distance in ontologies, $n$-grams, categorial grammars, link grammars and dependency tree structures can all be considered within the framework of positive operators and vector lattices.
%%\begin{itemize}
%%\item Several approaches to representing syntax in natural language, including probabilistic versions of context free formalisms such as categorial grammars and link grammars can be considered as positive operators, as can language modeling formalisms such as $n$-grams.
%%\item An ontology in the form of a lattice, together with a measure of semantic distance, can be used to build a vector lattice to represent meanings of words.
%%\item Vector representations such as those used in latent semantic analysis can also be considered as vector lattices
%%\item Dependency tree structures can be 
%%\end{itemize}

%\section{A Philosophy of Meaning}

%\section{Requirements for a Natural Language Algebra} 